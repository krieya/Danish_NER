{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crosslingual Transfer for Danish NER\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading data from disk\n",
    "\n",
    "All tokens are marked with BIO tags and the data contains four entity types: `LOC` (locations), `MISC` (miscellaneous), `ORG` (organizations) and `PER` (person names):\n",
    "\n",
    "```\n",
    "Berlingske      B-ORG\n",
    "Tidendes        O\n",
    "afslag          O\n",
    "kom             O\n",
    "først           O\n",
    "seks            O\n",
    "uger            O\n",
    "senere          O\n",
    "og              O\n",
    "lignede         O\n",
    "til             O\n",
    "forveksling     O\n",
    "afslaget        O\n",
    "fra             O\n",
    "Jyllands-Posten B-ORG\n",
    ".               O\n",
    "```\n",
    "\n",
    "Sentences are separated by blank lines.\n",
    "\n",
    "Define a function `read_data` which takes a file as input and returns a list of sentences. Each sentence is a list of pairs `(token, bio_tag)`, for example `(\"Jyllands-Posten\", \"B-ORG\")`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as path\n",
    "from collections import defaultdict\n",
    "\n",
    "def read_data(file):\n",
    "    \n",
    "    '''\n",
    "    Takes an open file and returns a list of sentences\n",
    "    '''\n",
    "    \n",
    "    sent_dict = defaultdict(list)\n",
    "    i = 0\n",
    "    for line in file:\n",
    "        if line.startswith(\"-DOCSTART-\"):\n",
    "            continue\n",
    "        if '\\t' in line:\n",
    "            word, tag = line.split('\\t')\n",
    "        \n",
    "        if line.startswith(\" \") or line.startswith(\"\\t\") or line == '\\n':\n",
    "            i += 1\n",
    "        else:\n",
    "            sent_dict[i].append((word, tag.strip(\"\\n\")))\n",
    "                    \n",
    "    return list(sent_dict.values())\n",
    "                \n",
    "\n",
    "import io\n",
    "\n",
    "# Tests\n",
    "test_string = \"Berlingske\\tB-ORG\"\n",
    "assert(read_data(io.StringIO(test_string)) == [[(\"Berlingske\",\"B-ORG\")]])\n",
    "\n",
    "\n",
    "test_string = \"\"\n",
    "assert not read_data(io.StringIO(test_string))\n",
    "\n",
    "test_string = '''hi\\tO\n",
    "nv\\tO\n",
    ".\\tO\n",
    " \\t \n",
    "hey\\tO\n",
    "!\\tO\n",
    " \\t \n",
    "'''\n",
    "assert len(read_data(io.StringIO(test_string))) == 2\n",
    "\n",
    "\n",
    "test_string = '''hi\\tO\n",
    "nv\\tO\n",
    ".\\tO\n",
    " \\t \n",
    "hey\\tO\n",
    "!\\tO\n",
    " \\t\n",
    " \\t \n",
    "'''\n",
    "assert len(read_data(io.StringIO(test_string))) == 2\n",
    "assert [] not in read_data(io.StringIO(test_string))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('På', 'O'), ('fredag', 'O'), ('har', 'O'), ('SID', 'B-ORG'), ('inviteret', 'O'), ('til', 'O'), ('reception', 'O'), ('i', 'O'), ('SID-huset', 'O'), ('i', 'O'), ('anledning', 'O'), ('af', 'O'), ('at', 'O'), ('formanden', 'O'), ('Kjeld', 'B-PER'), ('Christensen', 'I-PER'), ('går', 'O'), ('ind', 'O'), ('i', 'O'), ('de', 'O'), ('glade', 'O'), ('tressere', 'O'), ('.', 'O')]\n",
      "[('Hvor', 'O'), ('kommer', 'O'), ('julemanden', 'O'), ('fra', 'O'), ('?', 'O')]\n"
     ]
    }
   ],
   "source": [
    "danish_train = read_data(open(path.join(\"data\",\"danish-train.conll\")))\n",
    "danish_dev = read_data(open(path.join(\"data\",\"danish-dev.conll\")))\n",
    "danish_test = read_data(open(path.join(\"data\",\"danish-test.conll\")))\n",
    "\n",
    "print(danish_train[0])\n",
    "print(danish_dev[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting data into spaCy format\n",
    "\n",
    "\n",
    "The NER models in spaCy take training data in a specific format which differs from the BIO annotation in our files:\n",
    "\n",
    "```\n",
    "('På fredag har SID inviteret til reception i SID-huset i anledning af at formanden Kjeld Christensen går ind i de glade tressere .', {'entities': [[14, 17, 'ORG'], [82, 99, 'PER']]})\n",
    "```\n",
    "\n",
    "Each example is a pair where the first member is a sentence string like `'På fredag har SID inviteret til reception i SID-huset i anledning af at formanden Kjeld Christensen går ind i de glade tressere .'`. Note that the tokens in the sentence including punctuation are separated by spaces. The second member is a dictionary which specifies all named entities in a list `{'entities': [[14, 17, 'ORG'], [82, 99, 'PER']]}`.\n",
    "\n",
    "Each entity like `[14, 17, 'ORG']` gives the start index of the entity (`14` in this case), its end (`17`) and the type of the entity `ORG`. The organization here is \n",
    "\n",
    "```\n",
    "print('På fredag har SID inviteret til reception i SID-huset i anledning af at formanden Kjeld Christensen går ind i de glade tressere .'[14:17])\n",
    "\n",
    "SID\n",
    "```\n",
    "and the person is:\n",
    "```\n",
    "print('På fredag har SID inviteret til reception i SID-huset i anledning af at formanden Kjeld Christensen går ind i de glade tressere .'[82:99])\n",
    "\n",
    "Kjeld Christensen\n",
    "```\n",
    "\n",
    "The function below takes a dataset in BIO-format and returns it in spaCy format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entity(tag):\n",
    "    return tag[2:]\n",
    "\n",
    "def get_spacy_ner_data(data):\n",
    "    result = []\n",
    "    \n",
    "    for sent in data:\n",
    "        final_dict = dict()\n",
    "        final_dict['entities'] = []\n",
    "        \n",
    "        entities = defaultdict(list)\n",
    "        i = 0\n",
    "        \n",
    "        curr_idx = 0\n",
    "        \n",
    "        tokens = []\n",
    "        for pair in sent:\n",
    "            token, tag = pair\n",
    "            tokens.append(token)\n",
    "            \n",
    "            if tag.startswith(\"B-\"):\n",
    "                i += 1\n",
    "                curr_type = get_entity(tag)              \n",
    "                entities[(curr_type, i)].append(curr_idx)\n",
    "                entities[(curr_type, i)].append(curr_idx + len(token))\n",
    "            \n",
    "            elif tag.startswith(\"I-\"):\n",
    "                I_type = get_entity(tag)\n",
    "                if I_type == curr_type:\n",
    "                    entities[(curr_type, i)].append(curr_idx + len(token))\n",
    "                               \n",
    "            curr_idx += len(token) + 1\n",
    "        \n",
    "        if entities:\n",
    "            for key, values in entities.items():\n",
    "                ent = [values[0], values[-1], key[0]]\n",
    "                    \n",
    "                final_dict['entities'].append(ent)\n",
    "        \n",
    "        result.append((\" \".join(tokens), final_dict))\n",
    "   \n",
    "    return result\n",
    "\n",
    "# Tests\n",
    "test_data = [[(\"The\",\"O\"),\n",
    "              (\"dog\",\"O\"),\n",
    "              (\"slept\",\"O\"),\n",
    "              (\".\",\"O\")]]\n",
    "assert(get_spacy_ner_data(test_data) == [('The dog slept .',{'entities':[]})])\n",
    "\n",
    "test_data = [[(\"The\",\"O\"),\n",
    "              (\"dog\",\"B-ORG\"),\n",
    "              (\"slept\",\"O\"),\n",
    "              (\".\",\"O\")]]\n",
    "assert(get_spacy_ner_data(test_data) == [('The dog slept .',{'entities':[[4, 7, 'ORG']]})])\n",
    "\n",
    "\n",
    "test_data = [[(\"The\",\"O\"),\n",
    "              (\"dog\",\"B-ORG\"),\n",
    "              (\"slept\",\"B-ORG\"),\n",
    "              (\"Henry\", \"B-ORG\"),\n",
    "              (\".\",\"O\")]]\n",
    "\n",
    "assert(get_spacy_ner_data(test_data) == [('The dog slept Henry .',{'entities':[[4, 7, 'ORG'], [8, 13, 'ORG'], [14, 19, 'ORG']]})])\n",
    "\n",
    "\n",
    "test_data = [[(\"The\",\"O\"),\n",
    "              (\"dog\",\"B-ORG\"),\n",
    "              (\"slept\",\"I-ORG\"),\n",
    "              (\"Henry\", \"B-ORG\"),\n",
    "              (\".\",\"O\")]]\n",
    "\n",
    "assert(get_spacy_ner_data(test_data) == [('The dog slept Henry .',{'entities':[[4, 13, 'ORG'], [14, 19, 'ORG']]})])\n",
    "\n",
    "\n",
    "test_data = [[('Anne', 'B-PER'),\n",
    "              ('showed', 'O'),\n",
    "              ('Sue', 'B-PER'),\n",
    "              ('Mengqiu Huang', 'B-PER'),\n",
    "              (\"'s\", 'O'),\n",
    "              ('new', 'O'),\n",
    "              ('painting', 'O')]]\n",
    "\n",
    "assert get_spacy_ner_data(test_data)[0][1] == {'entities': [[0, 4, 'PER'], [12, 15, 'PER'], [16, 29, 'PER']]}\n",
    "\n",
    "\n",
    "test_data = [[(\"The\",\"O\"),\n",
    "              (\"dog\",\"B-ORG\"),\n",
    "              (\"slept\",\"I-ORG\"),\n",
    "              (\"Henry\", \"I-ORG\"),\n",
    "              (\".\",\"O\")]]\n",
    "\n",
    "assert get_spacy_ner_data(test_data)[0][1] == {'entities': [[4, 19, 'ORG']]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('På fredag har SID inviteret til reception i SID-huset i anledning af at formanden Kjeld Christensen går ind i de glade tressere .', {'entities': [[14, 17, 'ORG'], [82, 99, 'PER']]})\n"
     ]
    }
   ],
   "source": [
    "danish_spacy_train = get_spacy_ner_data(danish_train)\n",
    "danish_spacy_dev = get_spacy_ner_data(danish_dev)\n",
    "danish_spacy_test = get_spacy_ner_data(danish_test)\n",
    "\n",
    "print(danish_spacy_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation for NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sys_spacy_data,gold_spacy_data):\n",
    "    precision, recall, fscore = 0, 0, 0\n",
    "\n",
    "    p_total, r_total = 0, 0\n",
    "    \n",
    "    correct = 0\n",
    "    \n",
    "    for sys, gold in zip(sys_spacy_data, gold_spacy_data):\n",
    "        sys_ent = sys[1]['entities']\n",
    "        gold_ent = gold[1]['entities']\n",
    "        \n",
    "        p_total += len(sys_ent)\n",
    "        r_total += len(gold_ent)\n",
    "        \n",
    "        for r in sys_ent:\n",
    "            if r in gold_ent:\n",
    "                correct += 1\n",
    "\n",
    "    precision = correct / p_total \n",
    "    recall = correct / r_total \n",
    "    \n",
    "    if precision == 0 and recall == 0:\n",
    "        fscore = 0\n",
    "    else:\n",
    "        fscore = 2 * precision * recall / (precision + recall)\n",
    "    \n",
    "    return precision * 100, recall * 100, fscore * 100\n",
    "\n",
    "# tests\n",
    "sys_data = [(\"word1 word2 word3 word4\",{\"entities\":[(0,5,\"PER\"),(12,17,\"LOC\")]}),\n",
    "            (\"word1 word2 word3 word4\",{\"entities\":[(6,11,\"ORG\")]})]\n",
    "\n",
    "gold_data = [(\"word1 word2 word3 word4\",{\"entities\":[(0,6,\"PER\"),(12,17,\"LOC\")]}),\n",
    "             (\"word1 word2 word3 word4\",{\"entities\":[]})]\n",
    "\n",
    "precision, recall, fscore = evaluate(sys_data,gold_data)\n",
    "assert(precision == 1.0/3 * 100)\n",
    "assert(recall    == 1.0/2 * 100)\n",
    "assert(fscore    == 2*1.0/3*1.0/2 / (1.0/3 + 1.0/2) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a NER model on the Danish data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing the NER model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy \n",
    "from spacy.util import minibatch, compounding\n",
    "from random import shuffle, seed\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def init_model(spacy_train_data, language):\n",
    "    model = spacy.blank(language)\n",
    "\n",
    "    seed(0)\n",
    "    np.random.seed(0)\n",
    "    spacy.util.fix_random_seed(0)\n",
    "    torch.manual_seed(0)\n",
    "    \n",
    "    if \"ner\" not in model.pipe_names:\n",
    "        ner = model.create_pipe(\"ner\")\n",
    "        model.add_pipe(ner, last=True)\n",
    "    else:\n",
    "        ner = model.get_pipe(\"ner\")\n",
    "    \n",
    "    for _, annotations in spacy_train_data:\n",
    "        for ent in annotations.get(\"entities\"):\n",
    "            ner.add_label(ent[2])\n",
    "\n",
    "    # Make sure we're only training the NER component of the pipeline\n",
    "    pipe_exceptions = [\"ner\"]\n",
    "    other_pipes = [pipe for pipe in model.pipe_names if pipe not in pipe_exceptions]\n",
    "\n",
    "    # Start training so that we can use the model to annotate data\n",
    "    model.disable_pipes(*other_pipes)\n",
    "    optimizer = model.begin_training()\n",
    "    return model, optimizer\n",
    "\n",
    "danish_untrained_model, _ = init_model(danish_spacy_train,\"da\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotating the development set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate(spacy_data, model):\n",
    "    result = []\n",
    "    \n",
    "    for sent in spacy_data:\n",
    "        entities_dict = {'entities': []}\n",
    "        annotated = model(sent[0])\n",
    "        ents = annotated.ents\n",
    "        if ents:\n",
    "            for ent in ents:\n",
    "                entities_dict['entities'].append([ent.start_char, ent.end_char, ent.label_])\n",
    "        \n",
    "        result.append((sent[0], entities_dict))    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the NER model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import random\n",
    "\n",
    "def train(spacy_train_data, spacy_dev_data, epochs,language):\n",
    "    # Initialize model and get optimizer\n",
    "    model, optimizer = init_model(spacy_train_data,language)\n",
    "    \n",
    "    # Make sure we don't permute the original training data.\n",
    "    spacy_train_data = deepcopy(spacy_train_data)\n",
    "    \n",
    "    for itn in range(epochs):\n",
    "        losses = {}\n",
    "        \n",
    "        random.shuffle(spacy_train_data)\n",
    "        batches = minibatch(spacy_train_data, size=compounding(4.0, 32.0, 1.001))\n",
    "        for batch in batches:\n",
    "            texts, annotations = zip(*batch)\n",
    "            model.update(\n",
    "                texts,  # batch of texts\n",
    "                annotations,  # batch of annotations\n",
    "                drop=0.1,  # dropout - make it harder to memorise data\n",
    "                losses=losses,\n",
    "            )\n",
    "           \n",
    "        # Evaluate model\n",
    "        print(\"Loss for epoch %u: %.4f\" % (itn+1, losses[\"ner\"]))\n",
    "        spacy_dev_sys = annotate(spacy_dev_data, model)\n",
    "        p, r, f = evaluate(spacy_dev_sys,spacy_dev_data)\n",
    "        print(\"  PRECISION: %.2f%%, RECALL: %.2f%%, F-SCORE: %.2f%%\" % (p,r,f))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a NER model on the Danish training data for 20 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1: 678.1348\n",
      "  PRECISION: 27.27%, RECALL: 20.75%, F-SCORE: 23.57%\n",
      "Loss for epoch 2: 210.5326\n",
      "  PRECISION: 31.90%, RECALL: 29.97%, F-SCORE: 30.91%\n",
      "Loss for epoch 3: 125.7944\n",
      "  PRECISION: 51.61%, RECALL: 41.50%, F-SCORE: 46.01%\n",
      "Loss for epoch 4: 81.3938\n",
      "  PRECISION: 45.30%, RECALL: 47.26%, F-SCORE: 46.26%\n",
      "Loss for epoch 5: 59.5731\n",
      "  PRECISION: 44.92%, RECALL: 39.48%, F-SCORE: 42.02%\n",
      "Loss for epoch 6: 43.0145\n",
      "  PRECISION: 40.79%, RECALL: 41.50%, F-SCORE: 41.14%\n",
      "Loss for epoch 7: 46.8049\n",
      "  PRECISION: 40.58%, RECALL: 40.35%, F-SCORE: 40.46%\n",
      "Loss for epoch 8: 30.4313\n",
      "  PRECISION: 42.06%, RECALL: 43.52%, F-SCORE: 42.78%\n",
      "Loss for epoch 9: 24.2765\n",
      "  PRECISION: 40.91%, RECALL: 41.50%, F-SCORE: 41.20%\n",
      "Loss for epoch 10: 15.3588\n",
      "  PRECISION: 45.86%, RECALL: 44.67%, F-SCORE: 45.26%\n",
      "Loss for epoch 11: 13.2599\n",
      "  PRECISION: 49.43%, RECALL: 49.57%, F-SCORE: 49.50%\n",
      "Loss for epoch 12: 8.2948\n",
      "  PRECISION: 41.99%, RECALL: 46.11%, F-SCORE: 43.96%\n",
      "Loss for epoch 13: 13.0894\n",
      "  PRECISION: 42.64%, RECALL: 40.92%, F-SCORE: 41.76%\n",
      "Loss for epoch 14: 6.6051\n",
      "  PRECISION: 41.14%, RECALL: 41.50%, F-SCORE: 41.32%\n",
      "Loss for epoch 15: 2.4978\n",
      "  PRECISION: 41.53%, RECALL: 42.36%, F-SCORE: 41.94%\n",
      "Loss for epoch 16: 3.1490\n",
      "  PRECISION: 39.94%, RECALL: 39.48%, F-SCORE: 39.71%\n",
      "Loss for epoch 17: 5.6518\n",
      "  PRECISION: 46.18%, RECALL: 43.52%, F-SCORE: 44.81%\n",
      "Loss for epoch 18: 2.2455\n",
      "  PRECISION: 50.84%, RECALL: 43.52%, F-SCORE: 46.89%\n",
      "Loss for epoch 19: 0.0112\n",
      "  PRECISION: 49.69%, RECALL: 46.11%, F-SCORE: 47.83%\n",
      "Loss for epoch 20: 4.5937\n",
      "  PRECISION: 49.10%, RECALL: 47.26%, F-SCORE: 48.16%\n",
      "\n",
      "Evaluating model on development set:\n",
      "  PRECISION: 49.10%, RECALL: 47.26%, F-SCORE: 48.16%\n"
     ]
    }
   ],
   "source": [
    "danish_model = train(danish_spacy_train,danish_spacy_dev,20,\"da\")\n",
    "print()\n",
    "print(\"Evaluating model on development set:\")\n",
    "danish_spacy_dev_sys = annotate(danish_spacy_dev, danish_model)\n",
    "p, r, f = evaluate(danish_spacy_dev_sys,danish_spacy_dev)\n",
    "print(\"  PRECISION: %.2f%%, RECALL: %.2f%%, F-SCORE: %.2f%%\" % (p,r,f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pocket learning\n",
    "\n",
    "Re-write training algorithm to [\"pocket\"](https://en.wikipedia.org/wiki/Perceptron#Variants) the best model so far. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "def train(spacy_train_data, spacy_dev_data, epochs,language):\n",
    "    # Initialize model and get optimizer\n",
    "    model, optimizer = init_model(spacy_train_data,language)\n",
    "    \n",
    "    # Make sure we don't permute the original training data.\n",
    "    spacy_train_data = deepcopy(spacy_train_data)\n",
    "    \n",
    "    best_model = None\n",
    "    current_fscore = 0\n",
    "    \n",
    "    \n",
    "    for itn in range(epochs):\n",
    "        losses = {}\n",
    "\n",
    "        random.shuffle(spacy_train_data)\n",
    "        batches = minibatch(spacy_train_data, size=compounding(4.0, 32.0, 1.001))\n",
    "        for batch in batches:\n",
    "            texts, annotations = zip(*batch)\n",
    "            model.update(\n",
    "                texts,  # batch of texts\n",
    "                annotations,  # batch of annotations\n",
    "                drop=0.1,  # dropout - make it harder to memorise data\n",
    "                losses=losses,\n",
    "            )\n",
    "\n",
    "        print(\"Loss for epoch %u: %.4f\" % (itn+1, losses[\"ner\"]))\n",
    "        spacy_dev_sys = annotate(spacy_dev_data, model)\n",
    "        p, r, f = evaluate(spacy_dev_sys,spacy_dev_data)\n",
    "        print(\"  PRECISION: %.2f%%, RECALL: %.2f%%, F-SCORE: %.2f%%\" % (p,r,f))\n",
    "        if f > current_fscore:\n",
    "            current_fscore = f\n",
    "            best_model = deepcopy(model)\n",
    "    \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-train the Danish model for 20 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/terence/opt/anaconda3/lib/python3.7/runpy.py:193: UserWarning: [W020] Unnamed vectors. This won't allow multiple vectors models to be loaded. (Shape: (200008, 64))\n",
      "  \"__main__\", mod_spec)\n",
      "/Users/terence/opt/anaconda3/lib/python3.7/runpy.py:193: UserWarning: [W019] Changing vectors name from spacy_pretrained_vectors to spacy_pretrained_vectors_200008, to avoid clash with previously loaded vectors. See Issue #3853.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1: 677.7490\n",
      "  PRECISION: 23.47%, RECALL: 6.63%, F-SCORE: 10.34%\n",
      "Loss for epoch 2: 225.6457\n",
      "  PRECISION: 32.17%, RECALL: 31.99%, F-SCORE: 32.08%\n",
      "Loss for epoch 3: 115.5140\n",
      "  PRECISION: 53.77%, RECALL: 45.24%, F-SCORE: 49.14%\n",
      "Loss for epoch 4: 84.2517\n",
      "  PRECISION: 49.27%, RECALL: 48.70%, F-SCORE: 48.99%\n",
      "Loss for epoch 5: 69.0883\n",
      "  PRECISION: 48.68%, RECALL: 53.31%, F-SCORE: 50.89%\n",
      "Loss for epoch 6: 52.4823\n",
      "  PRECISION: 52.07%, RECALL: 50.72%, F-SCORE: 51.39%\n",
      "Loss for epoch 7: 28.4619\n",
      "  PRECISION: 56.39%, RECALL: 52.16%, F-SCORE: 54.19%\n",
      "Loss for epoch 8: 26.9459\n",
      "  PRECISION: 49.72%, RECALL: 51.01%, F-SCORE: 50.36%\n",
      "Loss for epoch 9: 23.1341\n",
      "  PRECISION: 52.23%, RECALL: 53.89%, F-SCORE: 53.05%\n",
      "Loss for epoch 10: 13.9116\n",
      "  PRECISION: 51.46%, RECALL: 55.91%, F-SCORE: 53.59%\n",
      "Loss for epoch 11: 14.2523\n",
      "  PRECISION: 54.43%, RECALL: 51.30%, F-SCORE: 52.82%\n",
      "Loss for epoch 12: 4.4521\n",
      "  PRECISION: 52.99%, RECALL: 51.01%, F-SCORE: 51.98%\n",
      "Loss for epoch 13: 3.0246\n",
      "  PRECISION: 50.79%, RECALL: 55.91%, F-SCORE: 53.22%\n",
      "Loss for epoch 14: 2.0731\n",
      "  PRECISION: 51.58%, RECALL: 51.87%, F-SCORE: 51.72%\n",
      "Loss for epoch 15: 0.6641\n",
      "  PRECISION: 53.64%, RECALL: 40.35%, F-SCORE: 46.05%\n",
      "Loss for epoch 16: 4.0652\n",
      "  PRECISION: 54.78%, RECALL: 49.57%, F-SCORE: 52.04%\n",
      "Loss for epoch 17: 2.0327\n",
      "  PRECISION: 56.71%, RECALL: 48.70%, F-SCORE: 52.40%\n",
      "Loss for epoch 18: 3.4092\n",
      "  PRECISION: 54.28%, RECALL: 47.55%, F-SCORE: 50.69%\n",
      "Loss for epoch 19: 0.1104\n",
      "  PRECISION: 50.80%, RECALL: 54.76%, F-SCORE: 52.70%\n",
      "Loss for epoch 20: 0.0114\n",
      "  PRECISION: 51.86%, RECALL: 52.16%, F-SCORE: 52.01%\n",
      "\n",
      "Evaluating model on development set:\n",
      "  PRECISION: 56.39%, RECALL: 52.16%, F-SCORE: 54.19%\n"
     ]
    }
   ],
   "source": [
    "danish_model = train(danish_spacy_train,danish_spacy_dev,20,\"da\")\n",
    "print()\n",
    "print(\"Evaluating model on development set:\")\n",
    "danish_spacy_dev_sys = annotate(danish_spacy_dev, danish_model)\n",
    "p, r, f = evaluate(danish_spacy_dev_sys,danish_spacy_dev)\n",
    "print(\"  PRECISION: %.2f%%, RECALL: %.2f%%, F-SCORE: %.2f%%\" % (p,r,f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding pretrained bilingual embeddings\n",
    "\n",
    "[spaCy documentation](https://spacy.io/api/vocab#from_disk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(spacy_train_data, language):\n",
    "    model = spacy.blank(language)\n",
    "\n",
    "    seed(0)\n",
    "    np.random.seed(0)\n",
    "    spacy.util.fix_random_seed(0)\n",
    "    torch.manual_seed(0)\n",
    "    \n",
    "    if \"ner\" not in model.pipe_names:\n",
    "        ner = model.create_pipe(\"ner\")\n",
    "        model.add_pipe(ner, last=True)\n",
    "    else:\n",
    "        ner = model.get_pipe(\"ner\")\n",
    "    \n",
    "    for _, annotations in spacy_train_data:\n",
    "        for ent in annotations.get(\"entities\"):\n",
    "            ner.add_label(ent[2])\n",
    "    \n",
    "    model.vocab.from_disk(\"data/vocab\")\n",
    "\n",
    "    # Make sure we're only training the NER component of the pipeline\n",
    "    pipe_exceptions = [\"ner\"]\n",
    "    other_pipes = [pipe for pipe in model.pipe_names if pipe not in pipe_exceptions]\n",
    "\n",
    "    # Start training so that we can use the model to annotate data\n",
    "    model.disable_pipes(*other_pipes)\n",
    "    optimizer = model.begin_training()\n",
    "\n",
    "    return model, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/terence/opt/anaconda3/lib/python3.7/runpy.py:193: UserWarning: [W020] Unnamed vectors. This won't allow multiple vectors models to be loaded. (Shape: (200008, 64))\n",
      "  \"__main__\", mod_spec)\n",
      "/Users/terence/opt/anaconda3/lib/python3.7/runpy.py:193: UserWarning: [W019] Changing vectors name from spacy_pretrained_vectors to spacy_pretrained_vectors_200008, to avoid clash with previously loaded vectors. See Issue #3853.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1: 652.7799\n",
      "  PRECISION: 28.57%, RECALL: 22.48%, F-SCORE: 25.16%\n",
      "Loss for epoch 2: 183.7652\n",
      "  PRECISION: 32.90%, RECALL: 29.11%, F-SCORE: 30.89%\n",
      "Loss for epoch 3: 127.5094\n",
      "  PRECISION: 47.60%, RECALL: 45.82%, F-SCORE: 46.70%\n",
      "Loss for epoch 4: 86.4522\n",
      "  PRECISION: 41.41%, RECALL: 50.72%, F-SCORE: 45.60%\n",
      "Loss for epoch 5: 84.4125\n",
      "  PRECISION: 51.46%, RECALL: 50.72%, F-SCORE: 51.09%\n",
      "Loss for epoch 6: 50.0252\n",
      "  PRECISION: 53.95%, RECALL: 47.26%, F-SCORE: 50.38%\n",
      "Loss for epoch 7: 35.0164\n",
      "  PRECISION: 53.17%, RECALL: 55.62%, F-SCORE: 54.37%\n",
      "Loss for epoch 8: 30.1722\n",
      "  PRECISION: 48.25%, RECALL: 47.55%, F-SCORE: 47.90%\n",
      "Loss for epoch 9: 26.7410\n",
      "  PRECISION: 56.29%, RECALL: 51.59%, F-SCORE: 53.83%\n",
      "Loss for epoch 10: 13.7209\n",
      "  PRECISION: 52.94%, RECALL: 49.28%, F-SCORE: 51.04%\n",
      "Loss for epoch 11: 12.2926\n",
      "  PRECISION: 56.33%, RECALL: 53.89%, F-SCORE: 55.08%\n",
      "Loss for epoch 12: 13.2249\n",
      "  PRECISION: 54.50%, RECALL: 57.64%, F-SCORE: 56.02%\n",
      "Loss for epoch 13: 6.0137\n",
      "  PRECISION: 50.89%, RECALL: 49.57%, F-SCORE: 50.22%\n",
      "Loss for epoch 14: 10.3392\n",
      "  PRECISION: 53.91%, RECALL: 57.64%, F-SCORE: 55.71%\n",
      "Loss for epoch 15: 7.5408\n",
      "  PRECISION: 49.59%, RECALL: 52.74%, F-SCORE: 51.12%\n",
      "Loss for epoch 16: 0.1073\n",
      "  PRECISION: 54.57%, RECALL: 55.04%, F-SCORE: 54.81%\n",
      "Loss for epoch 17: 4.9960\n",
      "  PRECISION: 52.38%, RECALL: 53.89%, F-SCORE: 53.12%\n",
      "Loss for epoch 18: 4.5104\n",
      "  PRECISION: 55.87%, RECALL: 50.72%, F-SCORE: 53.17%\n",
      "Loss for epoch 19: 0.1010\n",
      "  PRECISION: 56.40%, RECALL: 55.91%, F-SCORE: 56.15%\n",
      "Loss for epoch 20: 0.0141\n",
      "  PRECISION: 59.15%, RECALL: 55.91%, F-SCORE: 57.48%\n",
      "\n",
      "Evaluating model on development set:\n",
      "  PRECISION: 59.15%, RECALL: 55.91%, F-SCORE: 57.48%\n"
     ]
    }
   ],
   "source": [
    "danish_model = train(danish_spacy_train,danish_spacy_dev,20,\"da\")\n",
    "print()\n",
    "print(\"Evaluating model on development set:\")\n",
    "danish_spacy_dev_sys = annotate(danish_spacy_dev, danish_model)\n",
    "p, r, f = evaluate(danish_spacy_dev_sys,danish_spacy_dev)\n",
    "print(\"  PRECISION: %.2f%%, RECALL: %.2f%%, F-SCORE: %.2f%%\" % (p,r,f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training an English NER model and fine-tuning on Danish data\n",
    "\n",
    "Train an English NER system on the [CoNLL 2003 dataset](https://www.aclweb.org/anthology/W03-0419.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/terence/opt/anaconda3/lib/python3.7/runpy.py:193: UserWarning: [W020] Unnamed vectors. This won't allow multiple vectors models to be loaded. (Shape: (200008, 64))\n",
      "  \"__main__\", mod_spec)\n",
      "/Users/terence/opt/anaconda3/lib/python3.7/runpy.py:193: UserWarning: [W019] Changing vectors name from spacy_pretrained_vectors to spacy_pretrained_vectors_200008, to avoid clash with previously loaded vectors. See Issue #3853.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1: 11086.7898\n",
      "  PRECISION: 88.80%, RECALL: 88.10%, F-SCORE: 88.45%\n",
      "Loss for epoch 2: 6077.8644\n",
      "  PRECISION: 89.70%, RECALL: 89.58%, F-SCORE: 89.64%\n",
      "Loss for epoch 3: 4595.8670\n",
      "  PRECISION: 89.50%, RECALL: 89.70%, F-SCORE: 89.60%\n",
      "Loss for epoch 4: 3642.7214\n",
      "  PRECISION: 90.34%, RECALL: 89.99%, F-SCORE: 90.16%\n",
      "Loss for epoch 5: 2964.1685\n",
      "  PRECISION: 90.76%, RECALL: 90.41%, F-SCORE: 90.58%\n"
     ]
    }
   ],
   "source": [
    "english_train = read_data(open(path.join(\"data\",\"english-train.conll\")))\n",
    "english_dev = read_data(open(path.join(\"data\",\"english-dev.conll\")))\n",
    "\n",
    "english_spacy_train = get_spacy_ner_data(english_train)\n",
    "english_spacy_dev = get_spacy_ner_data(english_dev)\n",
    "\n",
    "english_model = train(english_spacy_train,english_spacy_dev,5,\"en\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning the model on Danish data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for epoch 1: 224.5756\n",
      "  PRECISION: 58.59%, RECALL: 59.94%, F-SCORE: 59.26%\n",
      "Loss for epoch 2: 74.6681\n",
      "  PRECISION: 61.94%, RECALL: 64.27%, F-SCORE: 63.08%\n",
      "Loss for epoch 3: 38.5355\n",
      "  PRECISION: 60.38%, RECALL: 63.69%, F-SCORE: 61.99%\n",
      "Loss for epoch 4: 11.4595\n",
      "  PRECISION: 58.27%, RECALL: 61.96%, F-SCORE: 60.06%\n",
      "Loss for epoch 5: 4.2907\n",
      "  PRECISION: 59.62%, RECALL: 62.54%, F-SCORE: 61.04%\n",
      "Loss for epoch 6: 1.7737\n",
      "  PRECISION: 60.11%, RECALL: 61.67%, F-SCORE: 60.88%\n",
      "Loss for epoch 7: 1.3902\n",
      "  PRECISION: 59.34%, RECALL: 62.25%, F-SCORE: 60.76%\n",
      "Loss for epoch 8: 0.0069\n",
      "  PRECISION: 61.03%, RECALL: 61.38%, F-SCORE: 61.21%\n",
      "Loss for epoch 9: 0.0001\n",
      "  PRECISION: 61.82%, RECALL: 62.54%, F-SCORE: 62.18%\n",
      "Loss for epoch 10: 0.0018\n",
      "  PRECISION: 61.05%, RECALL: 63.69%, F-SCORE: 62.34%\n",
      "Loss for epoch 11: 0.0003\n",
      "  PRECISION: 62.25%, RECALL: 63.69%, F-SCORE: 62.96%\n",
      "Loss for epoch 12: 0.0077\n",
      "  PRECISION: 61.94%, RECALL: 64.27%, F-SCORE: 63.08%\n",
      "Loss for epoch 13: 0.0007\n",
      "  PRECISION: 61.43%, RECALL: 64.27%, F-SCORE: 62.82%\n",
      "Loss for epoch 14: 0.0000\n",
      "  PRECISION: 61.84%, RECALL: 63.98%, F-SCORE: 62.89%\n",
      "Loss for epoch 15: 0.0001\n",
      "  PRECISION: 62.25%, RECALL: 63.69%, F-SCORE: 62.96%\n",
      "Loss for epoch 16: 0.0003\n",
      "  PRECISION: 61.90%, RECALL: 63.69%, F-SCORE: 62.78%\n",
      "Loss for epoch 17: 0.0002\n",
      "  PRECISION: 62.08%, RECALL: 63.69%, F-SCORE: 62.87%\n",
      "Loss for epoch 18: 0.0002\n",
      "  PRECISION: 62.08%, RECALL: 63.69%, F-SCORE: 62.87%\n",
      "Loss for epoch 19: 0.0002\n",
      "  PRECISION: 61.84%, RECALL: 63.98%, F-SCORE: 62.89%\n",
      "Loss for epoch 20: 0.0000\n",
      "  PRECISION: 61.84%, RECALL: 63.98%, F-SCORE: 62.89%\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "def retrain(spacy_train_data, spacy_dev_data, epochs,model,pretrained_fn):\n",
    "    # Make sure we don't permute the original training data.\n",
    "    spacy_train_data = deepcopy(spacy_train_data)\n",
    "    \n",
    "    model = deepcopy(model)\n",
    "    \n",
    "    for itn in range(epochs):\n",
    "        losses = {}\n",
    "\n",
    "        random.shuffle(spacy_train_data)\n",
    "        batches = minibatch(spacy_train_data, size=compounding(4.0, 32.0, 1.001))\n",
    "        for batch in batches:\n",
    "            texts, annotations = zip(*batch)\n",
    "            model.update(\n",
    "                texts,  # batch of texts\n",
    "                annotations,  # batch of annotations\n",
    "                drop=0.1,  # dropout - make it harder to memorise data\n",
    "                losses=losses,\n",
    "            )\n",
    "\n",
    "        \n",
    "        # Evaluate model\n",
    "        print(\"Loss for epoch %u: %.4f\" % (itn+1, losses[\"ner\"]))\n",
    "        spacy_dev_sys = annotate(spacy_dev_data, model)\n",
    "        p, r, f = evaluate(spacy_dev_sys,spacy_dev_data)\n",
    "        print(\"  PRECISION: %.2f%%, RECALL: %.2f%%, F-SCORE: %.2f%%\" % (p,r,f))\n",
    "    return model\n",
    "\n",
    "transfer_model = retrain(danish_spacy_train, danish_spacy_dev, 20,english_model,\"data/vocab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating basic Danish model on test set:\n",
      "  PRECISION: 58.67%, RECALL: 52.05%, F-SCORE: 55.16%\n",
      "\n",
      "Evaluating basic transfer model on test set:\n",
      "  PRECISION: 62.37%, RECALL: 63.33%, F-SCORE: 62.85%\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluating basic Danish model on test set:\")\n",
    "danish_spacy_test_sys_basic = annotate(danish_spacy_test, danish_model)\n",
    "p, r, f = evaluate(danish_spacy_test_sys_basic,danish_spacy_test)\n",
    "print(\"  PRECISION: %.2f%%, RECALL: %.2f%%, F-SCORE: %.2f%%\" % (p,r,f))\n",
    "print()\n",
    "\n",
    "print(\"Evaluating basic transfer model on test set:\")\n",
    "danish_spacy_test_sys_transfer = annotate(danish_spacy_test, transfer_model)\n",
    "p, r, f = evaluate(danish_spacy_test_sys_transfer,danish_spacy_test)\n",
    "print(\"  PRECISION: %.2f%%, RECALL: %.2f%%, F-SCORE: %.2f%%\" % (p,r,f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing the results\n",
    "\n",
    "* Does the transfer model get better at identifying names which are similar in the Danish and English NER data?\n",
    "* Deos the transfer model identify more purely Danish names which are not found by the basic model? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic:\n",
      "Rusland | ORG\n",
      "Transfer:\n",
      "Rusland | LOC\n",
      "Gold:\n",
      "Rusland | LOC\n",
      "-----\n",
      "Basic:\n",
      "Ruslands | ORG\n",
      "Transfer:\n",
      "Ruslands | MISC\n",
      "Gold:\n",
      "Ruslands | LOC\n",
      "-----\n",
      "Basic:\n",
      "Skjern | LOC\n",
      "Transfer:\n",
      "Skjern | PER\n",
      "Gold:\n",
      "Skjern | LOC\n",
      "-----\n",
      "Basic:\n",
      "Skjerns | ORG\n",
      "Transfer:\n",
      "Skjerns | MISC\n",
      "Gold:\n",
      "Skjerns | LOC\n",
      "-----\n",
      "Basic:\n",
      "Max | ORG\n",
      "Transfer:\n",
      "Max | PER\n",
      "Gold:\n",
      "Max | PER\n",
      "-----\n",
      "Basic:\n",
      "Henning Dyremose | PER\n",
      "Transfer:\n",
      "Finansmininister Henning Dyremose | PER\n",
      "Gold:\n",
      "Henning Dyremose | PER\n",
      "-----\n",
      "Basic:\n",
      "Europa | LOC\n",
      "Transfer:\n",
      "Europa Cup | MISC\n",
      "Gold:\n",
      "Europa Cup | MISC\n",
      "-----\n",
      "Basic:\n",
      "Atansa Stokus | MISC\n",
      "Transfer:\n",
      "Atansa Stokus | PER\n",
      "Gold:\n",
      "Atansa Stokus | PER\n",
      "-----\n",
      "Basic:\n",
      "Eduardas Potashinskas | MISC\n",
      "Transfer:\n",
      "Eduardas Potashinskas | PER\n",
      "Gold:\n",
      "Eduardas Potashinskas | PER\n",
      "-----\n",
      "Basic:\n",
      "Københavns Kommune | PER\n",
      "Transfer:\n",
      "Københavns | MISC\n",
      "Gold:\n",
      "Københavns Kommune | ORG\n",
      "-----\n",
      "Basic:\n",
      "Brøndbys | LOC\n",
      "Transfer:\n",
      "Brøndbys | MISC\n",
      "Gold:\n",
      "Brøndbys | ORG\n",
      "-----\n",
      "Basic:\n",
      "Lyngby | LOC\n",
      "Transfer:\n",
      "Lyngby | ORG\n",
      "Gold:\n",
      "Lyngby | ORG\n",
      "-----\n",
      "Basic:\n",
      "Steen Uno | PER\n",
      "Transfer:\n",
      "Steen Uno | ORG\n",
      "Gold:\n",
      "Steen Uno | PER\n",
      "-----\n",
      "Basic:\n",
      "Københavns Amtsråd | PER\n",
      "Transfer:\n",
      "Københavns Amtsråd | ORG\n",
      "Gold:\n",
      "Københavns Amtsråd | ORG\n",
      "-----\n",
      "Basic:\n",
      "Københavns Amts | PER\n",
      "Transfer:\n",
      "Københavns Amts | LOC\n",
      "Gold:\n",
      "Københavns Amts sygehusafdeling for multihandicappede | ORG\n",
      "-----\n",
      "Basic:\n",
      "Vangedehuse | LOC\n",
      "Transfer:\n",
      "Vangedehuse | MISC\n",
      "Gold:\n",
      "Vangedehuse | LOC\n",
      "-----\n",
      "Basic:\n",
      "Eddie | ORG\n",
      "Transfer:\n",
      "Eddie | PER\n",
      "Gold:\n",
      "Eddie | PER\n",
      "-----\n",
      "Basic:\n",
      "Jensen | ORG\n",
      "Transfer:\n",
      "Jensen | PER\n",
      "Gold:\n",
      "Jensen | PER\n",
      "-----\n",
      "Basic:\n",
      "Pernille | LOC\n",
      "Transfer:\n",
      "Pernille | PER\n",
      "Gold:\n",
      "Pernille | PER\n",
      "-----\n",
      "Basic:\n",
      "Ulla | LOC\n",
      "Transfer:\n",
      "Ulla | PER\n",
      "Gold:\n",
      "Ulla | PER\n",
      "-----\n",
      "Basic:\n",
      "Pernille | LOC\n",
      "Transfer:\n",
      "Pernille | PER\n",
      "Gold:\n",
      "Pernille | PER\n",
      "-----\n",
      "Basic:\n",
      "Ejby | LOC\n",
      "Transfer:\n",
      "Ejby | ORG\n",
      "Gold:\n",
      "Ejby | LOC\n",
      "-----\n",
      "Basic:\n",
      "Tuborg | ORG\n",
      "Transfer:\n",
      "Hof | LOC\n",
      "Gold:\n",
      "Tuborg | MISC\n",
      "-----\n",
      "Basic:\n",
      "Schlüter | PER\n",
      "Transfer:\n",
      "Schlüter | ORG\n",
      "Gold:\n",
      "Schlüter | PER\n",
      "-----\n",
      "Basic:\n",
      "Castorama | ORG\n",
      "Transfer:\n",
      "Castorama | PER\n",
      "Gold:\n",
      "Castorama | ORG\n",
      "-----\n",
      "Basic:\n",
      "Panasonic | LOC\n",
      "Transfer:\n",
      "Panasonic | ORG\n",
      "Gold:\n",
      "Panasonic | ORG\n",
      "-----\n",
      "Basic:\n",
      "Clas | LOC\n",
      "Transfer:\n",
      "Clas | PER\n",
      "Gold:\n",
      "Clas | ORG\n",
      "-----\n",
      "Basic:\n",
      "Buckler | LOC\n",
      "Transfer:\n",
      "Buckler | PER\n",
      "Gold:\n",
      "Buckler | ORG\n",
      "-----\n",
      "Basic:\n",
      "Lemond | ORG\n",
      "Transfer:\n",
      "Lemond | PER\n",
      "Gold:\n",
      "Lemond | ORG\n",
      "-----\n",
      "Basic:\n",
      "Alcala | PER\n",
      "Transfer:\n",
      "Alcala | ORG\n",
      "Gold:\n",
      "Alcala | ORG\n",
      "-----\n",
      "Basic:\n",
      "Ivan Madsen | PER\n",
      "Transfer:\n",
      "Rutechef Ivan Madsen | PER\n",
      "Gold:\n",
      "Ivan Madsen | PER\n",
      "-----\n",
      "Basic:\n",
      "Odense Teaters | PER\n",
      "Transfer:\n",
      "Odense Teaters | ORG\n",
      "Gold:\n",
      "Odense | LOC\n",
      "-----\n",
      "Basic:\n",
      "Vedbæk Boldklub | PER\n",
      "Transfer:\n",
      "Vedbæk | LOC\n",
      "Gold:\n",
      "Vedbæk | LOC\n",
      "-----\n",
      "Basic:\n",
      "Lvov | PER\n",
      "Transfer:\n",
      "Lvov | MISC\n",
      "Gold:\n",
      "Lvov | LOC\n",
      "-----\n",
      "Basic:\n",
      "Ricardo | LOC\n",
      "Transfer:\n",
      "Ricardo | PER\n",
      "Gold:\n",
      "Ricardo | PER\n",
      "-----\n",
      "Basic:\n",
      "Orwell | ORG\n",
      "Transfer:\n",
      "Orwell | PER\n",
      "Gold:\n",
      "Orwell | PER\n",
      "-----\n",
      "Basic:\n",
      "Enghavevej | LOC\n",
      "Transfer:\n",
      "Enghavevej | ORG\n",
      "Gold:\n",
      "Enghavevej | LOC\n",
      "-----\n",
      "Basic:\n",
      "Serbiens | LOC\n",
      "Transfer:\n",
      "Serbiens | ORG\n",
      "Gold:\n",
      "Serbiens | LOC\n",
      "-----\n",
      "Basic:\n",
      "Bosnien-Hercegovina | ORG\n",
      "Transfer:\n",
      "Bosnien | LOC\n",
      "Gold:\n",
      "Bosnien-Hercegovina | LOC\n",
      "-----\n",
      "Basic:\n",
      "Serbiens | LOC\n",
      "Transfer:\n",
      "Serbiens | ORG\n",
      "Gold:\n",
      "Serbiens | LOC\n",
      "-----\n",
      "Basic:\n",
      "Stanley Marcus' | PER\n",
      "Transfer:\n",
      "Stanley Marcus | PER\n",
      "Gold:\n",
      "Stanley Marcus' | PER\n",
      "-----\n",
      "Basic:\n",
      "Aalborg Stiftstidendes | PER\n",
      "Transfer:\n",
      "Aalborg | LOC\n",
      "Gold:\n",
      "Aalborg | LOC\n",
      "-----\n",
      "Basic:\n",
      "Danmarks | LOC\n",
      "Transfer:\n",
      "Danmarks Radios | ORG\n",
      "Gold:\n",
      "Danmarks Radios | ORG\n",
      "-----\n",
      "Basic:\n",
      "Kim Christofte | MISC\n",
      "Transfer:\n",
      "Kim Christofte | PER\n",
      "Gold:\n",
      "Kim Christofte | PER\n",
      "-----\n",
      "Basic:\n",
      "Varde Bank | PER\n",
      "Transfer:\n",
      "Varde Bank | ORG\n",
      "Gold:\n",
      "Varde Bank | ORG\n",
      "-----\n",
      "Basic:\n",
      "Die Onkels | LOC\n",
      "Transfer:\n",
      "Die | MISC\n",
      "Gold:\n",
      "Die Onkels | MISC\n",
      "-----\n",
      "Basic:\n",
      "Brian Nielsen | PER\n",
      "Transfer:\n",
      "Supersværvægteren Brian Nielsen | PER\n",
      "Gold:\n",
      "Brian Nielsen | PER\n",
      "-----\n",
      "Basic:\n",
      "Barcelona | LOC\n",
      "Transfer:\n",
      "Barcelona | ORG\n",
      "Gold:\n",
      "Barcelona | LOC\n",
      "-----\n",
      "Basic:\n",
      "R. Lin | LOC\n",
      "Transfer:\n",
      "R. Lin | PER\n",
      "Gold:\n",
      "R. Lin | PER\n",
      "-----\n",
      "Basic:\n",
      "Lykke | MISC\n",
      "Transfer:\n",
      "Lykke | PER\n",
      "Gold:\n",
      "Lykke | MISC\n",
      "-----\n",
      "Basic:\n",
      "Elvis | LOC\n",
      "Transfer:\n",
      "Elvis | PER\n",
      "Gold:\n",
      "Elvis | PER\n",
      "-----\n",
      "Basic:\n",
      "Vatra Romanesca | MISC\n",
      "Transfer:\n",
      "Vatra Romanesca | PER\n",
      "Gold:\n",
      "Vatra Romanesca | PER\n",
      "-----\n",
      "Basic:\n",
      "Nørrebro Bibliotek | ORG\n",
      "Transfer:\n",
      "Nørrebro | LOC\n",
      "Gold:\n",
      "Nørrebro | LOC\n",
      "-----\n",
      "Basic:\n",
      "Accumulator Invest | PER\n",
      "Transfer:\n",
      "Accumulator Invest | LOC\n",
      "Gold:\n",
      "Accumulator Invest | ORG\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(len(danish_spacy_test_sys_basic)):\n",
    "    basic_entities = danish_spacy_test_sys_basic[i][1]['entities']\n",
    "    transfer_entities = danish_spacy_test_sys_transfer[i][1]['entities']\n",
    "    gold_entities = danish_spacy_test[i][1]['entities']\n",
    "    \n",
    "    if len(basic_entities) == len(transfer_entities) and len(basic_entities) == len(gold_entities) and len(basic_entities) != 0:\n",
    "        for basic, transfer, gold in zip(basic_entities, transfer_entities, gold_entities):\n",
    "            if basic != transfer:\n",
    "            \n",
    "                print(\"Basic:\")\n",
    "                print(danish_spacy_test_sys_basic[i][0][basic[0]:basic[1]], \"|\", basic[2])\n",
    "                print(\"Transfer:\")\n",
    "                print(danish_spacy_test_sys_transfer[i][0][transfer[0]:transfer[1]],\"|\",  transfer[2])\n",
    "                print(\"Gold:\")\n",
    "                print(danish_spacy_test[i][0][gold[0]:gold[1]], \"|\", gold[2])\n",
    "                print(\"-----\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discussion:\n",
    "\n",
    "By inspecting the examples printed above, the transfer model do have better predictions on the name entities that are similar to English words. Examples below are the names that transfer model predicts correctly but the basic model gets wrong:\n",
    "- Ruslands: it is similar to \"Rus-\" and \"lands\" in English, which means \"Russian lands\"\n",
    "- Europa Cup: these are the same word forms as in English\n",
    "- Eddie: the same as the English name \"Eddie\"\n",
    "- Panasonic: the same as the English brand name\n",
    "\n",
    "In these cases, the transfer model could predict the labels more accurately. However, if the name entities are purely Danish, the transfer model does not necessarily perform better than the basic model. Examples below are the names that transfer model predicts wrong but the basic model gets correctly:\n",
    "\n",
    "- Skjern: this is the name of a Denmark town, which is purely Danish.\n",
    "- Ejby: this is again the name of a Denmark town.\n",
    "- Schlüter: this is a name in purely Danish\n",
    "\n",
    "Which means, the transfer model is able to predict the name entities that contains English elements/structures, but for entities in pure Danish, it may not be able to transfer the \"knowledges\" from English to apply for it. However, through my inspection, I can see that lots of Danish name entities actually contain English elements, which could be the reason that the transfer model overall performs better than the basic model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
